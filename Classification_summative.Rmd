install.packages("caret")
install.packages("caTools")
install.packages("ggplot2")
install.packages("corrplot")
install.packages("ggcorrplot")
install.packages("ggpubr")
install.packages("glmnet", dependencies=TRUE)
install.packages("randomForest")
install.packages("ROCR")
install.packages("reshape")

library(ggplot2)
library(ggpubr)
library(corrplot)
library(ggcorrplot)
library(caret)
library(caTools)
library(glmnet)
library(randomForest)
library(pROC)
library(reshape)

# Import the dataset 
data <- read.csv(file='hotels.csv')
head(data)

# Summary of the dataset
summary(data)
str(data)

# Missing Values
colSums(is.na(data))

# Feature selection 

We select all the numeric features and all the categorical features which have 12 or less categories. We also change the datatype of the is_cancelled and is_repeated_guest to factor as these are categorical variables.

keep <- c("is_canceled", "adults", "children", "babies", "meal", "is_repeated_guest", "previous_cancellations", "previous_bookings_not_canceled", "booking_changes", "deposit_type", "customer_type", "adr", "total_of_special_requests")

df <- data[ ,keep]
str(df)

df[,"is_canceled"] <- factor(df[,"is_canceled"])
df[, "is_repeated_guest"] <- factor(df[,"is_repeated_guest"])

str(df)

# Remove the missing values
# There were four missing values in the children column 
df <- na.omit(df)
colSums(is.na(df))

str(df)

# Number of booking that was not cancelled
sum(df$is_canceled == 0)/length(df$is_canceled)

# Number of cancelled booking 
sum(df$is_canceled == 1)/length(df$is_canceled)


# Plotting
# Plots of the categorical variables
plot1 <- ggplot(df, aes(x=is_canceled)) + geom_bar()
plot2 <- ggplot(df, aes(x=meal)) + geom_bar()
plot3 <- ggplot(df, aes(x=customer_type)) + geom_bar()
plot4 <- ggplot(df, aes(x=deposit_type)) + geom_bar()
plot5 <- ggplot(df, aes(x=is_repeated_guest)) + geom_bar()
ggarrange(plot1, plot2, plot3, plot4, plot5)

# Plot the correlation among the numerical datatypes
corr_mat <- cor(df[, unlist(lapply(df, is.numeric))])
corr_mat
ggcorrplot(corr_mat, hc.order = TRUE, type = "upper", outline.color = "white")

# Train-test split and one-hot encode the data
set.seed(101) 
sample = sample.split(df$is_canceled, SplitRatio=.80)
train = subset(df, sample == TRUE)
test  = subset(df, sample == FALSE)
dim(train)
dim(test)

# Simple logistic regression model
model_1 <- glm(is_canceled ~ ., data=train, family='binomial')
summary(model_1)
probs_1 <- predict(model_1, test, type="response")
model1.pred <- ifelse(probs_1 > 0.5, 1, 0)
model1.pred
confusionMatrix(factor(model1.pred), test$is_canceled)

reg.roc <- roc(test$is_canceled, probs_1)
plot(reg.roc)
auc(reg.roc)

## Plot the confusion matrix 
## taken from https://stackoverflow.com/questions/23891140/r-how-to-visualize-confusion-matrix-using-the-caret-package

draw_confusion_matrix <- function(cm) {

  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('CONFUSION MATRIX', cex.main=2)

  # create the matrix 
  rect(150, 430, 240, 370, col='#3F97D0')
  text(195, 435, 'not canceled', cex=1.2)
  rect(250, 430, 340, 370, col='#F7AD50')
  text(295, 435, 'canceled', cex=1.2)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
  text(245, 450, 'Actual', cex=1.3, font=2)
  rect(150, 305, 240, 365, col='#F7AD50')
  rect(250, 305, 340, 365, col='#3F97D0')
  text(140, 400, 'not canceled', cex=1.2, srt=90)
  text(140, 335, 'canceled', cex=1.2, srt=90)

  # add in the cm results 
  res <- as.numeric(cm$table)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')

  # add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
  text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
  text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
  text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
  text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
  text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)

  # add in the accuracy information 
  text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
  text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
  text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}  

draw_confusion_matrix(confusionMatrix(factor(model1.pred), test$is_canceled))

# Lasso regression with cross validation
## We apply the cross validation with the penelized regression
set.seed(101)
X <- model.matrix(is_canceled~., train)
Y <- train$is_canceled

cv.lasso <- cv.glmnet(X, Y, alpha=1, family="binomial")
model_lasso <- glmnet(X, Y, alpha=1, family="binomial", lambda=cv.lasso$lambda.min)

# Make predictions on the test data
X_test <- model.matrix(is_canceled~., test)
probs_lasso <- predict(model_lasso, X_test)

## Initial guess for the prob is 0.5
lasso.pred <- ifelse(probs_lasso > 0.5, 1, 0)
confusionMatrix(factor(lasso.pred), test$is_canceled)

# Model accuracy
mean(lasso.pred == test$is_canceled)

## Get the best cutoff for the best accuracy value
lasso.roc <- roc(test$is_canceled, probs_lasso)
plot(lasso.roc)
auc(lasso.roc)

# Random forest classifier
rf <- randomForest(is_canceled~., train)
pred_rf <- predict(rf, test, "prob")
confusionMatrix(pred_rf, test$is_canceled)

rf.roc <- roc(test$is_canceled, pred_rf[,2])
plot(rf.roc)
auc(rf.roc)

draw_confusion_matrix(confusionMatrix(pred_rf, test$is_canceled))

# Feature importance 
feature_imp <- data.frame(rownames(rf$importance), rf$importance)
feature_imp <- feature_imp[order(-feature_imp$MeanDecreaseGini),]
colnames(feature_imp) <- c("Features", "MeanDecreaseGini")

ggplot(feature_imp, aes(reorder(Features, MeanDecreaseGini), MeanDecreaseGini)) + geom_col() +
  coord_flip() + labs(title="Feature Importance", x="Features", y="Mean Decrease Gini")
  
# Feature importance 2

feature_imp <- data.frame(rownames(rf$importance), rf$importance)
feature_imp <- feature_imp[order(-feature_imp$MeanDecreaseGini),]
colnames(feature_imp) <- c("Features", "MeanDecreaseGini")

ggplot(feature_imp, aes(reorder(Features, MeanDecreaseGini), MeanDecreaseGini)) + geom_col() +
  coord_flip() + labs(x="Variables", y="Score")

## According to the above plot the most important features are "deposit_type", "previous_cancellations", "total_of_special_requests", "adr"
We select these data features for further hyperparameter tuning

keep2 <- c("deposit_type", "previous_cancellations", "total_of_special_requests", "adr", "is_canceled")
df_2 <- df[,keep2]

set.seed(101) 
sample = sample.split(df_2$is_canceled, SplitRatio=.80)
train_2 = subset(df_2, sample == TRUE)
test_2  = subset(df_2, sample == FALSE)

# Simple logistic regression model with reduced dataset
model_2 <- glm(is_canceled ~ ., data=train_2, family='binomial')
summary(model_2)
probs_2 <- predict(model_2, test_2, type="response")
model2.pred <- ifelse(probs_2 > 0.5, 1, 0)
model2.pred
confusionMatrix(factor(model2.pred), test_2$is_canceled)

draw_confusion_matrix(confusionMatrix(factor(model2.pred), test_2$is_canceled))

# Lasso regression with cross val (reduced dataset)
set.seed(101)
X_2 <- model.matrix(is_canceled~., train_2)
Y_2 <- train_2$is_canceled

cv.lasso_2 <- cv.glmnet(X_2, Y_2, alpha=1, family="binomial")
model_lasso_2 <- glmnet(X_2, Y_2, alpha=1, family="binomial", lambda=cv.lasso_2$lambda.min)

# Make predictions on the test data
X_test_2 <- model.matrix(is_canceled~., test_2)
probs_lasso_2 <- predict(model_lasso_2, X_test_2)

## Initial guess for the prob is 0.5
lasso.pred_2 <- ifelse(probs_lasso_2 > 0.5, 1, 0)
confusionMatrix(factor(lasso.pred_2), test_2$is_canceled)

draw_confusion_matrix(confusionMatrix(factor(lasso.pred_2), test_2$is_canceled))


# Random forest with limited number of trees and maxnodes

rf_2 <- randomForest(is_canceled~., train, ntree=100, maxnodes=32)
pred_rf2 <- predict(rf_2, test)
confusionMatrix(pred_rf2, test$is_canceled)

draw_confusion_matrix(confusionMatrix(pred_rf2, test$is_canceled))

## The above has slightly less accuracy but much better senstivity which means that it is able to predict a booking is not canceled very well. Better than other models.

# Random forest on reduced dataset
rf_3 <- randomForest(is_canceled~., train_2, ntree=100, maxnodes=32)
pred_rf3 <- predict(rf_3, test_2)
confusionMatrix(pred_rf3, test_2$is_canceled)

draw_confusion_matrix(confusionMatrix(pred_rf3, test_2$is_canceled))


## Compare the different models
##    Accuracy, Recall, Precision
x1 <- c(0.772, 0.972, 0.744)
x2 <- c(0.768, 0.994, 0.733)
x3 <- c(0.785, 0.935, 0.772)

names <- c("Logistic Reg.","Penalized Logistic Reg.","Random Forest")

data <- data.frame(cbind(c(0.772, 0.768, 0.785), c(0.972, 0.994, 0.935)), names)

data.m <- melt(data, id.vars='names')

#data <- data.frame(name=c("Logistic Reg.","Penalized Logistic Reg.","Random Forest"), accuracy=c(0.772, 0.768, 0.785))
#data$recall = c(0.972, 0.994, 0.935)
#data

ggplot(data.m, aes(names, value)) + 
  geom_bar(aes(fill = variable), position = "dodge", stat="identity") + geom_text(aes(label=value, group=value), position=position_dodge(0.9), vjust = 1.5)

